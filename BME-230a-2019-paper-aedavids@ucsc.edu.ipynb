{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A comparison of known cancer causing genes with those identified by a classifier trained on gene expression data.\n",
    "\n",
    "- BME 230A class project winter 2019\n",
    "- Andrew E. Davidson\n",
    "- [aedavids@ucsc.edu](mailto:aedavids@edu?subject=SimpleModel.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "A series of classifiers where trained on the [UCSC Xena Toil re-compute dataset](https://xenabrowser.net/datapages/?host=https://toil.xenahubs.net). \n",
    "It was known based on previous work that these classifiers should have high accuracy rate.\n",
    "It was also know that biologists have previous identified the gene sets associated with \n",
    "various forms of cancer. The goal of this project was to verify that the classifiers are consistent with known biology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "Typically data science projects develop models de novo. You start by mining an unknown data set. Your objective is to find structure in the data and create a data product. That is to say some sort of predictive model. It is important to understand the difference between a data product and a model. Models are of limited use. Often they may help you gain a better understanding of the relationships inherent in your data. A model is often considered good based on it's accuracy alone. Models are steps on the path to developing true data products. \n",
    "\n",
    "By contrast, data products are models that can be deployed at scale. Rarely is accuracy alone sufficient to decide if a model is deployable. In addiction to accuracy, most often data products must be explainable and generalize well.\n",
    "\n",
    "For data products to be deployable we must have confidence that our model generalize to the true targeted population. In the case of the Xena data set we need not only patients that are sick and may or may not have cancer but also to healthy individuals. We also need to account for demographic bias in the training data set.  Data products related to human behavior, for example recommender systems, or natural language tasks, must have mechanisms to identify population drift and processes for retrain.\n",
    "\n",
    "Explainability is often over looked when evaluating the deployability of a data product. Sometimes it is not required. For example consider a bad movie recommender. The viewer is not going to be harmed in anyway. For most data product the cost of false positives or negatives is high. For example consider a tumor/normal classifier or a model used to set insurance premiums. The new EU General Data Protection Regulation requires explainability for models with potential high mis-classification costs. It also seems unlike the the FDA will approve models that are not explainable. \n",
    "\n",
    "Lack of explainablity often limits the use of of Neural Networks. Fortunately neural network models based on Xena data set may be explainable. One approach for gaining insight into the workings of a trained model is to make predictions with hand crafter example and explore how these example activate the various layers of the neural network. [Andrej Karpath](https://cs.stanford.edu/people/karpathy/) used a similar approach to identify what kinds of images cause the filters of a convolutional neural network to activate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tumor/Normal classifier using Logistic Regression\n",
    "\n",
    "The output layer of our model implements the sigmoid function show in Figure 1. We want to identify genes that push the value of z towards the the far right or left of Figure 1 \n",
    "\n",
    "Based on equation (1) we can identify these genes by calculating their over all contribution to the value of z. The contribution is calculated as \n",
    "the mean value for each gene multiplied by its corresponding weight from our trained model \n",
    "\n",
    "Neural Network Activation Unit Equation \n",
    "\n",
    "$$ eq(1)\\ z\\ =\\ W^{ T }x $$\n",
    "\n",
    "$$ eq(2)\\ sigmoid\\ activation\\ (z) =\\frac { { 1 } }{ { 1 }+e^{ - z} } $$\n",
    "\n",
    "![aedwip](images/simpleModelEvaluationFig1.png \"images/simpleModelEvaluationFig1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure 2. \"Gene Contribution Distribution shows that as we might expect most of the 58,581 genes are ignored by our model\"\n",
    "\n",
    "we used a Z score threshold of 3 to identify genes that unusually large contribution to the value input into the sigmoid function. We use the term 'promoter' for genes that increase the sigmoid input value and the term 'inhibitor' for genes that decrease this input value.\n",
    "\n",
    "![images/simpleModelEvaluationFig2.png](images/simpleModelEvaluationFig2.png \"images/simpleModelEvaluationFig2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a small sample of genes found. Note they are not sorted by their contribution values\n",
    "```\n",
    "number normal promoters:211\n",
    "normal promoter[0:3]:Index(['ABCA10', 'ABCA6', 'ABCA8']\n",
    "\n",
    "number normal inhibitor:262\n",
    "normal inhibitor[0:3]:Index([['AC000089.3'], ['AC005255.3'], ['AC006386.1']\n",
    "\n",
    "number tumor promoters:270\n",
    "['AC000089.3', 'AC005255.3', 'AC006386.1']\n",
    "\n",
    "number tumor inhibitor:218\n",
    "['ABCA10'], ['ABCA6'], ['ABCA8']\n",
    "```\n",
    "\n",
    "<span style=\"color:red\">TODO:</span> confirm these genes know releation to cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references:\n",
    "* [simple logistic regression evaluation notebook](./simpleModelEvaluation.ipynb)\n",
    "* [simple logistic regression notebook](./simpleModel.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease Type Classifier Evaluation\n",
    "\n",
    "Method:\n",
    "\n",
    "The input size of our model is 58,581. Each value is a gene expression level. For each feature we make a prediction use a one-hot example. We then group the genes into sets based on the predicted disease type. We would expect the gene groups to correspond to know cancer related genes. Genes identified by the model that are not part of know pathways should be further explored.\n",
    "\n",
    "Figure 3. is a histogram showing the count of genes that individually classified as disease type. \n",
    "\n",
    "![images/diseaseTypeClassifierEvalFig1.png](images/diseaseTypeClassifierEvalFig1.png \"images/diseaseTypeClassifierEvalFig1.png\")\n",
    "\n",
    "To make the analysis easier we select the disease type with the fewest number of genes\"\n",
    "\n",
    "```\n",
    "disease type with smallest identified gene set:['Pancreatic Adenocarcinoma']\n",
    "number of genes in set:44\n",
    "       ['AC079235.1', 'AC087499.9', 'AC090311.1', 'AC231645.1',\n",
    "       'AL008708.1', 'AL354931.1', 'AL603650.4', 'ARAF', 'ATP6V1D',\n",
    "       'C14orf93', 'CLK3', 'CNPY3', 'CTC-258N23.3', 'CTD-2132H18.3',\n",
    "       'CYB5D2', 'FADS2P1', 'FBXW4', 'GOLGB1', 'HMGN1P5', 'KB-1582A10.2',\n",
    "       'LINC00616', 'LINC01035', 'MED10', 'MON1A', 'NEK3', 'PIN1',\n",
    "       'RFPL3-AS1_1', 'RNA5SP143', 'RNA5SP366', 'RNA5SP409', 'RNA5SP523',\n",
    "       'RNA5SP55', 'RNU6-1194P', 'RNU6-204P', 'RNU6-498P',\n",
    "       'RP11-626I20.3', 'RP11-74J13.9', 'SCARNA4', 'SF3B5', 'SGSM3',\n",
    "       'SLC35B3', 'SNORA70D', 'STX18', 'SUGT1']\n",
    "```\n",
    "\n",
    "<span style=\"color:red\">TODO: figure out how to mine biologic path way data.</span> We need to figure out how to map the gene sets we identify back to the know genes associated with each cancer type\n",
    "\n",
    "references:\n",
    "- [evaluation notebook diseaseTypeClassifierEval.ipynb](diseaseTypeClassifierEval.ipynb)\n",
    "- [data exploration, model creation notebook diseaseTypeClassifier.ipynb](diseaseTypeClassifier.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease Type Classifier using principle component analysis Evaluation\n",
    "<span style=\"color:red\">TODO double check out analysis for bugs</span>\n",
    "\n",
    "PCA and other dimensional reduction techniques are often used to reduce training time. My assumption was that given the performance of our model in a high dimensional space and the observation that our high dimensional models do not use the majority of gene expression features, we would expect to get similar results in a lower dimensional space.\n",
    "\n",
    "I was also surprised to discover that after fitting PCA to training set it was very slow to transform full feature test examples. This transformation should be done once as preprocessing step with the results cached to disk.\n",
    "\n",
    "We ran PCA on our training set accounting for 95% of the variance. This reduces size of our test set 58,581 features  to 5,895. This seems plausible given Fig 2. showed that most of the features in our full features models are ignored.\n",
    "\n",
    "Using the lower dimensional training set we trained a identical model used in our [diseaseTypeClassifier.ipynb notebook](./diseaseTypeClassifier.ipynb). As expected using the higher dimensional data set we had 2,343,278 trainable parameters. Using the lower dimensional data we have 235,838.\n",
    "\n",
    "Surprisingly there was a big drop in accuracy. Given we accounted for 95 % of the variance I expected a smaller drop\n",
    "\n",
    "High dimension accuracy\n",
    "\n",
    "```\n",
    "training accuracy:0.99\n",
    "    test accuracy:0.96\n",
    "```\n",
    "    \n",
    "Low dimension accuracy\n",
    "\n",
    "```\n",
    "training accuracy:0.81\n",
    "    test accuracy:0.73\n",
    "```\n",
    "\n",
    "The same neural architecture in a lower dimensional space suffers from high bias. In the high dimension model identified 'Pancreatic Adenocarcinoma' as the disease that had the smallest gene count at 44. While the low dimension model find 'Thymoma' with 800 genes\n",
    "\n",
    "Notice the large difference between 4igure 3 and figure 4. \n",
    "\n",
    "Figure 4.  Count of genes that individually classified as diesase type\"\n",
    "\n",
    "![images/dimensionaltyReducedDiseaseTypeClassifierFig1.png](images/dimensionaltyReducedDiseaseTypeClassifierFig1.png \"dimensionaltyReducedDiseaseTypeClassifierFig1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step\n",
    "1. double check out analysis for bugs\n",
    "\n",
    "2. figure out how to mine biologic path way data. We need to figure out how to map the gene sets we identify back to the know genes associated with each cancer type\n",
    "\n",
    "3. develop a better model for lower dimensional spaces\n",
    "\n",
    "4. Instead of using PCA try to learn a lower dimensional embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "All data and juypter notebook used to clean data, explore data, train and evaluate models is avalible at [https://github.com/AEDWIP/BME-230a](https://github.com/AEDWIP/BME-230a)\n",
    "\n",
    "you can view fully rendered version of the notebook complete with source code, text, and graphis by clicking on the *.ipynb notebook files on the github website\n",
    "\n",
    "## References:\n",
    "* [UCSC Xena Toil re-compute dataset](https://xenabrowser.net/datapages/host=https://toil.xenahubs.net)\n",
    "* [Nature Biotechnology publication: https://doi.org/10.1038/nbt.3772](https://doi.org/10.1038/nbt.3772)\n",
    "* [rcurrie/tumornormal/ingest notebook](https://github.com/rcurrie/tumornormal/blob/master/ingest.ipynb)\n",
    "    + used to create a local copy of the tcga_target_gtex.h5 data file from the Xena Toil re-compute dataset\n",
    "    + converts Covert Ensembl gene ids to Hugo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
