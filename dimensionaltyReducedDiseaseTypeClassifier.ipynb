{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionalty Reduced Disease Type Classifier\n",
    "\n",
    "- BME 230A class project winter 2019\n",
    "- Andrew E. Davidson\n",
    "- [aedavids@ucsc.edu](mailto:aedavids@edu?subject=SimpleModel.ipynb)\n",
    "\n",
    "ref:\n",
    "- [https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "- Chapter 8 \"Dimensionality Reduction in \"Hands-On Machine Learning with Scikit-learn & TensorFlow\" by Aurelien Geron\n",
    "- [https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60](https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/BME-230a\r\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ProgbarLogger\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense,Input,BatchNormalization, InputLayer, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD, Adadelta, Adagrad\n",
    "from keras.regularizers import L1L2\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "theMeaningOfLife = 42\n",
    "\n",
    "import keras\n",
    "if \"2.1.6\" != keras.__version__ :\n",
    "    emsg = \"ERROR keras version {} != 2.1.6, new version can not save and restore models\".format(keras.__version__)\n",
    "    raise ValueError(emsg)\n",
    "\n",
    "# add path to our local modules\n",
    "# assume they are in the same directory we launched the juypter server in\n",
    "# /home/ubuntu/BME-230a\n",
    "!pwd\n",
    "localModuleDir = \".\"\n",
    "sys.path.append(localModuleDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bme-230a-ebs/data/tcga_target_gtex.h5\n",
      "sourceDataFilePath:/bme-230a-ebs/data/tcga_target_gtex.h5\n",
      "CPU times: user 1.3 s, sys: 4.89 s, total: 6.18 s\n",
      "Wall time: 6.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rootDir = \"/bme-230a-ebs\"\n",
    "sourceDataFilePath = \"{}/data/tcga_target_gtex.h5\".format(rootDir)\n",
    "print(sourceDataFilePath)\n",
    "if not os.path.isfile(sourceDataFilePath) :\n",
    "    emsg = \"ERROR: {} not found\".format(sourceDataFilePath)\n",
    "    print(emsg)\n",
    "    print(\"change rootDir\")\n",
    "    sys.stdout.flush() # force error message to print\n",
    "    raise ValueError(emsg)\n",
    "    \n",
    "from loadData import loadCancerDiseaseTypeTidyDataSet\n",
    "\n",
    "ret = loadCancerDiseaseTypeTidyDataSet(rootDir)\n",
    "hugoIds, diseaseLabelEncoder, XTrainNumpy, yTrainNumpy, XTestNumpy, yTestNumpy = ret\n",
    "#XTestNumpy = yTestNumpy = None # clean up memory\n",
    "ret = None # clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrainNumpy.shape: (8424, 58581)\n",
      "yTrainNumpy.shape: (8424, 39)\n"
     ]
    }
   ],
   "source": [
    "print(\"XTrainNumpy.shape: {}\".format(XTrainNumpy.shape))\n",
    "print(\"yTrainNumpy.shape: {}\".format(yTrainNumpy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 24s, sys: 5.86 s, total: 13min 30s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95) # account for 95% of the variance\n",
    "XTrainReducedNumpy = pca.fit_transform(XTrainNumpy) \n",
    "XTrainNumpy = None # prevent bugs and clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(XTrainReducedNumpy:<class 'numpy.ndarray'>\n",
      "XTrainReducedNumpy.shape: (8424, 5895)\n",
      "pca.n_components_: 5895\n",
      "pca.explained_variance_: [2.15254990e+04 1.86303089e+04 1.64745828e+04 ... 8.72403837e+00\n",
      " 8.72019841e+00 8.71888428e+00]\n",
      "pca.explained_variance_ratio_: [7.24130749e-02 6.26734811e-02 5.54214888e-02 ... 2.93481904e-05\n",
      " 2.93352726e-05 2.93308518e-05]\n"
     ]
    }
   ],
   "source": [
    "print(\"type(XTrainReducedNumpy:{}\".format(type(XTrainReducedNumpy)))\n",
    "print(\"XTrainReducedNumpy.shape: {}\".format(XTrainReducedNumpy.shape))\n",
    "print(\"pca.n_components_: {}\".format(pca.n_components_))\n",
    "print(\"pca.explained_variance_: {}\".format(pca.explained_variance_))\n",
    "print(\"pca.explained_variance_ratio_: {}\".format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "this should be the same as the model in disaseTypeClassifier.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiClassClassifier(inputDim=None, outputDim=None, learningRate=0.001):\n",
    "    '''\n",
    "    aedwip\n",
    "    '''\n",
    "    classify = [\n",
    "        InputLayer(input_shape=(inputDim,)),\n",
    "        BatchNormalization(),\n",
    "        Dense(outputDim), # dot(input, kernel) + bias\n",
    "        Activation('softmax') \n",
    "    ]\n",
    "    \n",
    "    model = Sequential(classify)   \n",
    "    # https://keras.io/backend/#categorical_crossentropy\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learningRate), metrics=['accuracy']) \n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 5895)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5895)              23580     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 38)                224048    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 38)                0         \n",
      "=================================================================\n",
      "Total params: 247,628\n",
      "Trainable params: 235,838\n",
      "Non-trainable params: 11,790\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelName=\"reducedDiseaseClassifier\"\n",
    "# the first col of yTrainNumpy is the disease value. \n",
    "# numCases is size of the prediction output\n",
    "numCases = yTrainNumpy.shape[1] -1\n",
    "\n",
    "reducedDiseaseClassifierModel = multiClassClassifier(\n",
    "                                inputDim=XTrainReducedNumpy.shape[1],\n",
    "                                outputDim=numCases,\n",
    "                                )\n",
    "reducedDiseaseClassifierModel.summary()\n",
    "\n",
    "# https://keras.io/callbacks/\n",
    "checkPointPath=\"./models/{}.chkPt\".format(modelName)\n",
    "callbacks = [\n",
    "    # monitor valuse either 'acc' for accuracy or 'loss'\n",
    "    # 'val_loss' is loss on hold if valaidation_split is set\n",
    "    # 'loss' is loss on training\n",
    "    # same for 'acc' and 'val_acc'\n",
    "    EarlyStopping(monitor='loss', patience=2, verbose=0) \n",
    "    ,ModelCheckpoint(checkPointPath, monitor='loss', save_best_only=False, verbose=0)\n",
    "    # FIXME: progbar generates run time error\n",
    "    #,ProgbarLogger(count_mode='samples', stateful_metrics=None)\n",
    "]\n",
    "\n",
    "trainOneHots = yTrainNumpy[:,1:]\n",
    "history = reducedDiseaseClassifierModel.fit(XTrainReducedNumpy,trainOneHots,        \n",
    "                                        shuffle=None, # we already shuffled\n",
    "                                        epochs= 8, #20, #100\n",
    "                                        batch_size=1024, \n",
    "                                        # we already split the data         \n",
    "                                        validation_split=0.0, \n",
    "                                        verbose=0,\n",
    "                                        callbacks=callbacks\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
