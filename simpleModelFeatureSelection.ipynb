{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"simpleModelFeatureSelection.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"ocEO8IYXCZj4","colab_type":"text"},"cell_type":"markdown","source":["# Logistic Regression Tumor/normal Feature Selection\n","identify genes that maximal activate and compare to know cancer causing genes"]},{"metadata":{"id":"idsL7tUcCZj5","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","# fix random seed for reproducibility\n","theMeaningOfLife = 42\n","np.random.seed(theMeaningOfLife)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k_6phR2tCsnR","colab_type":"code","outputId":"9bc8c81c-d487-417f-f140-a6a1122b01ba","executionInfo":{"status":"ok","timestamp":1552177555520,"user_tz":480,"elapsed":1627,"user":{"displayName":"Andy Davidson","photoUrl":"https://lh4.googleusercontent.com/-gB9HZ-hNWHs/AAAAAAAAAAI/AAAAAAAABR8/h1ExrxwAg0k/s64/photo.jpg","userId":"01376457533882295996"}},"colab":{"base_uri":"https://localhost:8080/","height":205}},"cell_type":"code","source":["# running juypter notebook on my mac book pro was really slow\n","# work around, copied files to google drive\n","# google drive does not respect symbolic link I made \n","# ln -s rcurrie-tumornormal/data project/data\n","# work around move data \n","from google.colab import drive\n","drive.mount('/content/drive') # force_remount=True\n","projectDirUnix=\"drive/'My Drive'/GD_BME230a/project\"\n","projectDir=\"drive/My Drive/GD_BME230a/project\"\n","!ls $projectDirUnix"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"," data\t\t\t\t  README.md~\n"," loadData-googleSyncProblem.py\t  requirements.txt\n"," loadData-googleSyncProblem.py~   sandbox\n"," loadData.py\t\t\t  simpleModelFeatureSelection.ipynb\n"," models\t\t\t\t  simpleModel.ipynb\n"," __pycache__\t\t\t  simpleModel.pdf\n","'__pycache__ (1)'\t\t  t\n"," rcurrie-tumornormal\t\t  tensorFlowForDeepLearning\n"," README.md\t\t\t  test.h5\n"],"name":"stdout"}]},{"metadata":{"id":"P8GME6wXCZj8","colab_type":"code","outputId":"e724f980-760a-4d37-f129-e6bc1989f941","executionInfo":{"status":"ok","timestamp":1552177556484,"user_tz":480,"elapsed":2590,"user":{"displayName":"Andy Davidson","photoUrl":"https://lh4.googleusercontent.com/-gB9HZ-hNWHs/AAAAAAAAAAI/AAAAAAAABR8/h1ExrxwAg0k/s64/photo.jpg","userId":"01376457533882295996"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"cell_type":"code","source":["%%time\n","# load model\n","from keras.models import load_model\n","modelName=\"logisticRegressionTumorNormal\"\n","fullModelPath = \"{}/models/full{}.h5\".format(projectDir,modelName)\n","print(\"fullModelPath:{}\".format(fullModelPath))\n","\n","model = load_model(fullModelPath)\n","model.summary()\n","#model.get_weights()\n","print(\"model.optimizer:{}\".format(model.optimizer))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["fullModelPath:drive/My Drive/GD_BME230a/project/models/fulllogisticRegressionTumorNormal.h5\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","batch_normalization_1 (Batch (None, 58581)             234324    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 58582     \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 292,906\n","Trainable params: 175,744\n","Non-trainable params: 117,162\n","_________________________________________________________________\n","model.optimizer:<keras.optimizers.Adam object at 0x7f29cd57d0f0>\n","CPU times: user 879 ms, sys: 34.2 ms, total: 913 ms\n","Wall time: 929 ms\n"],"name":"stdout"}]},{"metadata":{"id":"sJE15rToQks6","colab_type":"code","colab":{}},"cell_type":"code","source":["_sourceDataFile = \"data/tcga_target_gtex.h5\"            \n","_tumorNormalFile = \"data/logisticRegressionTumorNormal.h5\" \n","\n","def loadTumorNormalData(projectDir):\n","    '''\n","     work around google sync issue\n","     \n","  # add local python modules to path\n","  import sys\n","  sys.path.append(projectDir)\n","\n","  # load data\n","  from loadData import loadTumorNormalData     \n","\n","    arguments:\n","        projectDir: root of project\n","    '''\n","    sourceDataFilePath = \"{}/{}\".format(projectDir, _sourceDataFile)\n","    print(\"sourceDataFilePath:{}\".format(sourceDataFilePath))\n","    store = pd.HDFStore(sourceDataFilePath, mode=\"r\")\n","    #print(\"{} source store.info():{}\".format(_sourceDataFile, store.info()))\n","    #print(\"{} store.keys():{}\".format(_sourceDataFile, store.keys()))\n","     \n","    # Load training set\n","    X = pd.read_hdf(sourceDataFilePath, \"expression\")\n","    Y = pd.read_hdf(sourceDataFilePath, \"labels\")\n"," \n","    # Convert tumor_normal  into numerical values \n","    from sklearn.preprocessing import LabelEncoder\n","     \n","    encoder = LabelEncoder()\n","    Y[\"tumor_normal_value\"] = pd.Series(encoder.fit_transform(Y[\"tumor_normal\"]), index=Y.index)\n","    #Y[[\"tumor_normal\",\"tumor_normal_value\"]].head(3)\n","     \n","    # Split into stratified training and test sets based on classes (i.e. tissue type) so that we have equal\n","    # proportions of each tissue type in the train and test sets\n","    from sklearn.model_selection import StratifiedShuffleSplit\n","    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=theMeaningOfLife)\n","    for train_index, test_index in split.split(X.values, Y[\"tumor_normal_value\"]):\n","        X_train, X_test = X.values[train_index], X.values[test_index]\n","        y_train, y_test = Y[\"tumor_normal_value\"][train_index], \\\n","                            Y[\"tumor_normal_value\"][test_index]  \n","     \n","    #print(\"AEDWIP X_train.shape:{}\".format(X_train.shape))\n","    #print(\"AEDWIP X.shape:{} len(X.columns):{}\".format(X.shape, len(X.columns)))\n","    \n","    # X_train and X_test are numpy arrays\n","    XTrainDF = pd.DataFrame(X_train, columns=X.columns)\n","    XTestDF = pd.DataFrame(X_test, columns=X.columns)\n","    \n","    # y_train and y_test are pandas series\n","    #yTrainDF = pd.DataFrame(y_train, columns=[\"tumor_normal_value\"])\n","    yTrainDF = pd.DataFrame(y_train, columns=[\"tumor_normal_value\"])\n","    yTrainDF.head(3)\n","    yTestDF = pd.DataFrame(y_test, columns=[\"tumor_normal_value\"])\n","    #return (X_train, y_train, X_test, y_test)\n","    #return (XTrainDF, yTrainDF, XTestDF, yTestDF)\n","    return (XTrainDF, y_train, XTestDF, y_test)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O1hLlUA6CZkB","colab_type":"code","outputId":"28b28d9e-fb92-4d40-a1fc-c3d272c9556f","executionInfo":{"status":"error","timestamp":1552177556969,"user_tz":480,"elapsed":3074,"user":{"displayName":"Andy Davidson","photoUrl":"https://lh4.googleusercontent.com/-gB9HZ-hNWHs/AAAAAAAAAAI/AAAAAAAABR8/h1ExrxwAg0k/s64/photo.jpg","userId":"01376457533882295996"}},"colab":{"base_uri":"https://localhost:8080/","height":1358}},"cell_type":"code","source":[" %%time\n","\n","# # add local python modules to path\n","# import sys\n","# sys.path.append(projectDir)\n","\n","# # load data\n","# from loadData import loadTumorNormalData\n","XTrainDF, yTrainSeries, _, _ = loadTumorNormalData(projectDir)\n","yTrainDF = pd.DataFrame(yTrainSeries)\n","yTrainSeries = None # clean up memory"],"execution_count":11,"outputs":[{"output_type":"stream","text":["sourceDataFilePath:drive/My Drive/GD_BME230a/project/data/tcga_target_gtex.h5\n"],"name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-5f599015f7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n# # add local python modules to path\\n# import sys\\n# sys.path.append(projectDir)\\n\\n# # load data\\n# from loadData import loadTumorNormalData\\nXTrainDF, yTrainSeries, _, _ = loadTumorNormalData(projectDir)\\nyTrainDF = pd.DataFrame(yTrainSeries)\\nyTrainSeries = None # clean up memory'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-10-5c71cafb597f>\u001b[0m in \u001b[0;36mloadTumorNormalData\u001b[0;34m(projectDir)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msourceDataFilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojectDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sourceDataFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sourceDataFilePath:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msourceDataFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msourceDataFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print(\"{} source store.info():{}\".format(_sourceDataFile, store.info()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#print(\"{} store.keys():{}\".format(_sourceDataFile, store.keys()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'can not be written'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tables/file.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tables/file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tables/utils.py\u001b[0m in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# The file should be readable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF_OK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"``%s`` does not exist\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"``%s`` is not a regular file\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: ``drive/My Drive/GD_BME230a/project/data/tcga_target_gtex.h5`` does not exist"]}]},{"metadata":{"id":"-GREOhTUCZkE","colab_type":"text"},"cell_type":"markdown","source":["# start eval"]},{"metadata":{"id":"NB3joVY_CZkF","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","# https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n","# We want to identify how much each feature contributes to Z the value passed to the activation layer\n","# its important that we use the batch_normalization layer from our logistic regression model\n","# else we will potentially scale the data to a distribution with a different mean and variance\n","\n","from keras.models import Model\n","\n","layerName=\"batch_normalization_1\"\n","normalizationModel = Model(inputs=model.input,\n","                                 outputs=model.get_layer(layerName).output)\n","\n","normalizedXTrain = normalizationModel.predict(XTrainDF)\n","\n","print(\"normalizedXTrain.shape:{}\".format(XTrainDF.shape))\n","print(\"type(normalizedXTrain):{}\".format(type(normalizedXTrain)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fmNbtZwFCZkH","colab_type":"code","colab":{}},"cell_type":"code","source":["# make sure batch normalization was applied\n","print(XTrainDF.iloc[0:5,0:5])\n","print()\n","print(normalizedXTrain[0:5,0:5])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M0h4Gb1OCZkL","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q8uJUkd1CZkN","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"wwKdOl8jCZkP","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","# create a new dataFrame that combines our features with out labels\n","# the index for XTrainDF are integers\n","# teh index for yTrainDF GTEX values e.g. GTEX-ZQG8-2426-SM-57WEE\n","normalizedXTrainDF = pd.DataFrame(normalizedXTrain, columns=XTrainDF.columns)\n","evalDF = pd.concat([normalizedXTrainDF, yTrainDF.reset_index(drop=True)], axis=1)\n","normalizedXTrainDF = None # clean up memory\n","XTrainDF = None # clean up memory"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8FRF-sAQCZkS","colab_type":"code","colab":{}},"cell_type":"code","source":["def calcStats(df, categoryColName, listOfAggFunctions):\n","    '''\n","    # https://stackoverflow.com/a/14734627/4586180\n","    1. groups rows by category\n","    2. applies the aggregate function to each group\n","    \n","    arguments:\n","        df:\n","            dataframe\n","            \n","        categoryColName:\n","            a string identifying the column to group by\n","            \n","        listOfAggFunctions:\n","            a list of string names of the aggrate function to run\n","    \n","    returns\n","        a dictionary. \n","            The key will be the classes in the col identifyied by categoryColName\n","            the value will be a dataframe with the aggragate values\n","        \n","    '''\n","    ret = dict()\n","    grouped = df.groupby(categoryColName)\n","    for key, group in grouped:\n","        stats = group.agg(listOfAggFunctions)\n","        ret[key] = stats\n","        \n","    return ret\n","        \n","   \n","# its easier to look at a small example than to explain what it calcStats() does\n","tn = pd.Series([\"normal\",\"tumor\",\"normal\",\"tumor\"], dtype=\"category\")\n","df = pd.DataFrame({\"gene1\":[1,2,3,4],\n","                   \"gene2\":[11, 22, 33, 44],\n","                   \"tumorNormal\":tn})\n","\n","ret = calcStats(df=df, categoryColName=\"tumorNormal\", listOfAggFunctions=['min', 'max', 'mean'])\n","print()\n","for key in ret.keys():\n","    print(\"key:{}\\n{}\\n\".format(key, ret[key]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pp6wqLQgCZkV","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","# for each class, calculate the mean value for each gene\n","statsDict = calcStats(df=evalDF, categoryColName=\"tumor_normal_value\", \n","                      listOfAggFunctions=['min', 'max', 'std', 'mean'])\n","evalDF = None # clean up memory"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K-Y0DcfkCZkX","colab_type":"code","colab":{}},"cell_type":"code","source":["# the keys are '0' and '1'\n","# AEDWIP make sure '0' is normal\n","normalDF = statsDict[0]\n","tumorDF = statsDict[1]\n","print(\"normalDF.shape:{}\".format(normalDF.shape))\n","print(\" tumorDF.shape:{}\".format(tumorDF.shape))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rS8A3FaPCZka","colab_type":"code","colab":{}},"cell_type":"code","source":["print(normalDF.iloc[0:4, 0:3])\n","last = normalDF.columns[-3:]\n","print()\n","print(normalDF.iloc[0:4,:].loc[:,last])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M8I3dE3ECZke","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","# identify which gene have the greatest effect on z\n","# by multiplying the means by the dense layer weight\n","denseLayer = model.get_layer('dense_1')\n","print(denseLayer.get_config())\n","weights = denseLayer.get_weights()\n","print(\"\\ntype(weights):{}\".format( type(weights) ))\n","print(\"len(weights):{}\".format(len(weights)))\n","print(\"weights[0][0:3]:{}\".format(weights[0][0:3]))\n","print(\"len(weights[0]):{}\".format(len(weights[0])))\n","print(\"type(weights[0]):{}\".format(type(weights[0])))\n","print(\"len(weights[1]):{}\".format(len(weights[1])))\n","coeficients = weights[0]\n","print(\"coeficients.shape:{}\".format(coeficients.shape))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8WU0x7AgCZkh","colab_type":"code","colab":{}},"cell_type":"code","source":["# last is the list of features,\n","last = normalDF.columns[:-1]\n","print(last)\n","\n","normalMeansSeries = normalDF.loc['mean', last]\n","\n","print(\"\\nnormalMeansSeries.head:\\n{}\".format(normalMeansSeries.head()))\n","      \n","print(\"\\nnormalMeansSeries.shape:{}\".format(normalMeansSeries.shape))\n","print(\"type(normalMeansSeries):{}\".format(type(normalMeansSeries)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eUKPx006CZkk","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.multiply.html\n","# element wise multiplication\n","v = normalMeansSeries.values\n","print(v.shape)\n","print(type(v))\n","\n","# total crushes memory swap goes to 19.85 GB\n","# <class 'numpy.ndarray'>\n","# CPU times: user 11.6 s, sys: 12.8 s, total: 24.4 s\n","# Wall time: 1min 15s\n","normalContribution = np.multiply(v,coeficients)\n","\n","# very slow\n","#normalContribution = np.multiply(normalMeansSeries,coeficients)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EsDZ2vulCZko","colab_type":"code","colab":{}},"cell_type":"code","source":["normalContribution[0:4]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zwbWWR6VCZkq","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","# bins = numpy.linspace(-10, 10, 100)\n","\n","plt.hist(normalContribution, bins=50, alpha=0.5, label='normal')\n","#pyplot.hist(y, bins=50, alpha=0.5, label='y')\n","plt.legend(loc='upper right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t3z0FsYcCZku","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"e1ELvlCBCZkv","colab_type":"code","colab":{}},"cell_type":"code","source":["# %%time\n","# # print(XTrainDF.shape)\n","# # print(yTrainDF.shape)\n","\n","# # print()\n","# # print(XTrainDF.head(2))\n","# # print(yTrainDF.head(2))\n","\n","# aaa = XTrainDF.iloc[0:3,0:3]\n","# bbb = yTrainDF.iloc[0:3,:]\n","\n","# print(\"aaa.shape():{}\".format(aaa.shape))\n","# print(\"bbb.shape():{}\".format(bbb.shape))\n","\n","# print(aaa)\n","# print(\"\\nbbb\")\n","# print(bbb)\n","# print(bbb.loc[:,'tumor_normal_value'].values)\n","\n","\n","# # append the label column\n","# ccc = pd.concat([aaa, bbb.reset_index(drop=True)], axis=1)\n","# print(\"\\n\\nccc:\\n{}\".format(ccc))\n","\n","# print(\"\\n\\n, did bbb loose its index?\\n{}\".format(bbb))\n","\n","\n","# # print(bbb.loc[:,'id'])\n","\n","# # aaa['tumor_normal_value'] = bbb.loc[:,'tumor_normal_value'].values\n","# # print(\"\\n\\n new and improve\\n:{}\".format(aaa))\n","# # print(\"\\n\\n******* did cat work\")\n","\n","# #print(pd.concat([aaa, bbb.values], axis=1))\n","# #print(evalDF)\n","# # print(evalDF.iloc[0:3, 0:3])\n","# # print(evalDF.iloc[0:3, -3])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"siOTe6P-CZky","colab_type":"code","colab":{}},"cell_type":"code","source":["# print(yTrainDF.columns)\n","# print(yTrainDF.iloc[0:3,-1].values)\n","# print(yTrainDF.index[0:3])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1EFMle8uCZk1","colab_type":"code","colab":{}},"cell_type":"code","source":["# # append label to training set\n","# XTrainDF['tumor_normal_value'] = yTrainDF.loc[:,'tumor_normal_value'].values\n","# print(XTrainDF.iloc[0:3,0:3])\n","# print()\n","# print(XTrainDF.iloc[0:3,-3])\n","# print()\n","# print(XTrainDF.loc[0:3, 'tumor_normal_value'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SV3efCE8CZk2","colab_type":"code","colab":{}},"cell_type":"code","source":["#statsDict = calcStats(evalDF, categoryColName=\"tumorNormal\", listOfAggFunctions=['min', 'max', 'mean'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0fGWkDrGCZk4","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"eTrQfgHiCZk6","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"AXlzolQMCZk8","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"h6z5phOECZk-","colab_type":"code","colab":{}},"cell_type":"code","source":["# %%time\n","# from sklearn.metrics import confusion_matrix\n","\n","# yPredict = model.predict(XTestDF)\n","# print(type(yPredict))\n","# print(yPredict[0:3])\n","\n","# yTestPredict = [1 if p > 0.5 else 0 for p in yPredict]\n","# #print(yTestPredict[0:3])\n","# cf = confusion_matrix(yTestDF, yTestPredict)\n","# print(cf)\n","# expected = [[1707, 13],[8, 2098]]\n","# np.testing.assert_array_equal(cf, expected)"],"execution_count":0,"outputs":[]}]}