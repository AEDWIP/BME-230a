{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocEO8IYXCZj4"
   },
   "source": [
    "# Logistic Regression Tumor/normal Feature Selection\n",
    "identify genes that maximal activate and compare to know cancer causing genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idsL7tUcCZj5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version should be Keras==2.1.6, new version can not save and restore models\n",
      "keras version:2.1.6\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(\"keras version should be Keras==2.1.6, new version can not save and restore models\")\n",
    "print(\"keras version:{}\".format(keras.__version__))\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "theMeaningOfLife = 42\n",
    "np.random.seed(theMeaningOfLife)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/BME-230a\r\n"
     ]
    }
   ],
   "source": [
    "# add path to our local modules\n",
    "# assume they are in the same directory we launched the juypter server in\n",
    "# /home/ubuntu/BME-230a\n",
    "!pwd\n",
    "localModuleDir = \".\"\n",
    "sys.path.append(localModuleDir)\n",
    "from loadData import loadTumorNormalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1627,
     "status": "ok",
     "timestamp": 1552177555520,
     "user": {
      "displayName": "Andy Davidson",
      "photoUrl": "https://lh4.googleusercontent.com/-gB9HZ-hNWHs/AAAAAAAAAAI/AAAAAAAABR8/h1ExrxwAg0k/s64/photo.jpg",
      "userId": "01376457533882295996"
     },
     "user_tz": 480
    },
    "id": "k_6phR2tCsnR",
    "outputId": "9bc8c81c-d487-417f-f140-a6a1122b01ba"
   },
   "outputs": [],
   "source": [
    "# save this code example \n",
    "\n",
    "# do not use google drive it is really slow\n",
    "# load data from AWS EBS volumne: BME-230a-project volume id: vol-026c8e33988a1475b\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive') # force_remount=True\n",
    "# projectDirUnix=\"drive/'My Drive'/GD_BME230a/project\"\n",
    "# projectDir=\"drive/My Drive/GD_BME230a/project\"\n",
    "# !ls $projectDirUnix\n",
    "\n",
    "# rootDir = \"/bme-230a-ebs\"\n",
    "# dataFile = \"{}/data/tcga_target_gtex.h5\".format(rootDir)\n",
    "# store = pd.HDFStore(dataFile, mode=\"r\")\n",
    "# print(\"store.info():{}\".format(store.info()))\n",
    "# print(\"store.keys():{}\".format(store.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sourceDataFilePath:/bme-230a-ebs/data/tcga_target_gtex.h5\n",
      "CPU times: user 1.24 s, sys: 4.7 s, total: 5.93 s\n",
      "Wall time: 5.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rootDir = \"/bme-230a-ebs\"\n",
    "XTrainDF, yTrainSeries, _, _ = loadTumorNormalData(rootDir)\n",
    "yTrainDF = pd.DataFrame(yTrainSeries)\n",
    "yTrainSeries = None # clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrainDF.shape:(15300, 58581)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5S_rRNA</th>\n",
       "      <th>5_8S_rRNA</th>\n",
       "      <th>7SK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.966041</td>\n",
       "      <td>-9.965816</td>\n",
       "      <td>-0.687321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.966041</td>\n",
       "      <td>-9.965816</td>\n",
       "      <td>-9.965881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.966041</td>\n",
       "      <td>-9.965816</td>\n",
       "      <td>-9.965881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    5S_rRNA  5_8S_rRNA       7SK\n",
       "0 -9.966041  -9.965816 -0.687321\n",
       "1 -9.966041  -9.965816 -9.965881\n",
       "2 -9.966041  -9.965816 -9.965881"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"XTrainDF.shape:{}\".format(XTrainDF.shape))\n",
    "XTrainDF.iloc[0:3,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2590,
     "status": "ok",
     "timestamp": 1552177556484,
     "user": {
      "displayName": "Andy Davidson",
      "photoUrl": "https://lh4.googleusercontent.com/-gB9HZ-hNWHs/AAAAAAAAAAI/AAAAAAAABR8/h1ExrxwAg0k/s64/photo.jpg",
      "userId": "01376457533882295996"
     },
     "user_tz": 480
    },
    "id": "P8GME6wXCZj8",
    "outputId": "e724f980-760a-4d37-f129-e6bc1989f941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullModelPath:/bme-230a-ebs/models/fulllogisticRegressionTumorNormal.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 58581)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 58581)             234324    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 58582     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 292,906\n",
      "Trainable params: 175,744\n",
      "Non-trainable params: 117,162\n",
      "_________________________________________________________________\n",
      "model.optimizer:<keras.optimizers.Adam object at 0x7fa30ab95da0>\n",
      "CPU times: user 680 ms, sys: 4 ms, total: 684 ms\n",
      "Wall time: 687 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load model\n",
    "from keras.models import load_model\n",
    "modelName=\"logisticRegressionTumorNormal\"\n",
    "modelRootDir = \"{}/models\".format(rootDir)\n",
    "fullModelPath = \"{}/full{}.h5\".format(modelRootDir, modelName)\n",
    "print(\"fullModelPath:{}\".format(fullModelPath))\n",
    "\n",
    "model = load_model(fullModelPath)\n",
    "model.summary()\n",
    "#model.get_weights()\n",
    "print(\"model.optimizer:{}\".format(model.optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GREOhTUCZkE"
   },
   "source": [
    "# start eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NB3joVY_CZkF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizedXTrain.shape:(15300, 58581)\n",
      "type(normalizedXTrain):<class 'numpy.ndarray'>\n",
      "CPU times: user 19.9 s, sys: 872 ms, total: 20.7 s\n",
      "Wall time: 6.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "# We want to identify how much each feature contributes to Z the value passed to the activation layer\n",
    "# its important that we use the batch_normalization layer from our logistic regression model\n",
    "# else we will potentially scale the data to a distribution with a different mean and variance\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "layerName=\"batch_normalization_1\"\n",
    "normalizationModel = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layerName).output)\n",
    "\n",
    "normalizedXTrain = normalizationModel.predict(XTrainDF)\n",
    "\n",
    "print(\"normalizedXTrain.shape:{}\".format(XTrainDF.shape))\n",
    "print(\"type(normalizedXTrain):{}\".format(type(normalizedXTrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmNbtZwFCZkH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5S_rRNA  5_8S_rRNA       7SK    A1BG  A1BG-AS1\n",
      "0 -9.966041  -9.965816 -0.687321  2.7487    0.6425\n",
      "1 -9.966041  -9.965816 -9.965881  1.7489    0.4552\n",
      "2 -9.966041  -9.965816 -9.965881  3.1393   -0.5332\n",
      "3 -9.966041  -9.965816 -9.965881  1.8957    0.3346\n",
      "4 -9.966041  -9.965816 -9.965881  6.1639    2.7951\n",
      "\n",
      "[[-0.22909236 -0.01842499  1.7634513  -0.4423349  -0.33213907]\n",
      " [-0.22909236 -0.01842499 -0.59044564 -0.93999165 -0.45341104]\n",
      " [-0.22909236 -0.01842499 -0.59044564 -0.24791121 -1.0933752 ]\n",
      " [-0.22909236 -0.01842499 -0.59044564 -0.86692107 -0.5314965 ]\n",
      " [-0.22909236 -0.01842499 -0.59044564  1.2576027   1.0616152 ]]\n"
     ]
    }
   ],
   "source": [
    "# make sure batch normalization was applied\n",
    "print(XTrainDF.iloc[0:5,0:5])\n",
    "print()\n",
    "print(normalizedXTrain[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwKdOl8jCZkP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.22 s, sys: 696 ms, total: 2.91 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a new dataFrame that combines our features with out labels\n",
    "# the index for XTrainDF are integers\n",
    "# teh index for yTrainDF GTEX values e.g. GTEX-ZQG8-2426-SM-57WEE\n",
    "normalizedXTrainDF = pd.DataFrame(normalizedXTrain, columns=XTrainDF.columns)\n",
    "evalTrainDF = pd.concat([normalizedXTrainDF, yTrainDF.reset_index(drop=True)], axis=1)\n",
    "yTrainDF = None # clean up memory\n",
    "normalizedXTrainDF = None # clean up memory\n",
    "XTrainDF = None # clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8FRF-sAQCZkS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "key:normal\n",
      "      gene1  gene2\n",
      "min     1.0   11.0\n",
      "max     3.0   33.0\n",
      "mean    2.0   22.0\n",
      "\n",
      "key:tumor\n",
      "      gene1  gene2\n",
      "min     2.0   22.0\n",
      "max     4.0   44.0\n",
      "mean    3.0   33.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calcStats(df, categoryColName, listOfAggFunctions):\n",
    "    '''\n",
    "    # https://stackoverflow.com/a/14734627/4586180\n",
    "    1. groups rows by category\n",
    "    2. applies the aggregate function to each group\n",
    "    \n",
    "    arguments:\n",
    "        df:\n",
    "            dataframe\n",
    "            \n",
    "        categoryColName:\n",
    "            a string identifying the column to group by\n",
    "            \n",
    "        listOfAggFunctions:\n",
    "            a list of string names of the aggrate function to run\n",
    "    \n",
    "    returns\n",
    "        a dictionary. \n",
    "            The key will be the classes in the col identifyied by categoryColName\n",
    "            the value will be a dataframe with the aggragate values\n",
    "        \n",
    "    '''\n",
    "    ret = dict()\n",
    "    grouped = df.groupby(categoryColName)\n",
    "    for key, group in grouped:\n",
    "        stats = group.agg(listOfAggFunctions)\n",
    "        ret[key] = stats\n",
    "        \n",
    "    return ret\n",
    "        \n",
    "   \n",
    "# small example that explains what it calcStats() does\n",
    "tn = pd.Series([\"normal\",\"tumor\",\"normal\",\"tumor\"], dtype=\"category\")\n",
    "df = pd.DataFrame({\"gene1\":[1,2,3,4],\n",
    "                   \"gene2\":[11, 22, 33, 44],\n",
    "                   \"tumorNormal\":tn})\n",
    "\n",
    "ret = calcStats(df=df, categoryColName=\"tumorNormal\", listOfAggFunctions=['min', 'max', 'mean'])\n",
    "print()\n",
    "for key in ret.keys():\n",
    "    print(\"key:{}\\n{}\\n\".format(key, ret[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pp6wqLQgCZkV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 884 ms, total: 1min 13s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for each class, calculate the mean value for each gene\n",
    "statsTrainDict = calcStats(df=evalTrainDF, categoryColName=\"tumor_normal_value\", \n",
    "                      listOfAggFunctions=['min', 'max', 'std', 'mean'])\n",
    "evalTrainDF = None # clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-Y0DcfkCZkX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalTrainDF.shape:(4, 58582)\n",
      " tumorTrainDF.shape:(4, 58582)\n"
     ]
    }
   ],
   "source": [
    "# the keys are '0' and '1'\n",
    "# AEDWIP make sure '0' is normal\n",
    "normalTrainDF = statsTrainDict[0]\n",
    "tumorTrainDF = statsTrainDict[1]\n",
    "print(\"normalTrainDF.shape:{}\".format(normalTrainDF.shape))\n",
    "print(\" tumorTrainDF.shape:{}\".format(tumorTrainDF.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rS8A3FaPCZka"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       5S_rRNA  5_8S_rRNA       7SK\n",
      "min  -0.229092  -0.018425 -0.590446\n",
      "max   5.554689  68.263947  2.793195\n",
      "std   1.095426   0.823410  1.058365\n",
      "mean  0.045851  -0.008494  0.078725\n",
      "\n",
      "        uc_338  yR211F11.2  tumor_normal_value\n",
      "min  -2.405998   -0.343928                 0.0\n",
      "max   1.359166    4.647242                 0.0\n",
      "std   0.827414    0.876714                 0.0\n",
      "mean  0.305524   -0.090991                 0.0\n"
     ]
    }
   ],
   "source": [
    "print(normalTrainDF.iloc[0:4, 0:3])\n",
    "last3ColLabels = normalTrainDF.columns[-3:]\n",
    "print()\n",
    "print(normalTrainDF.iloc[0:4,:].loc[:,last3ColLabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8I3dE3ECZke"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'dense_1', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "\n",
      "type(weights):<class 'list'>\n",
      "len(weights):2\n",
      "weights[0][0:3]:[[ 0.00080593]\n",
      " [-0.00365209]\n",
      " [ 0.00453593]]\n",
      "len(weights[0]):58581\n",
      "type(weights[0]):<class 'numpy.ndarray'>\n",
      "len(weights[1]):1\n",
      "coeficients.shape:(58581, 1)\n",
      "CPU times: user 8 ms, sys: 4 ms, total: 12 ms\n",
      "Wall time: 8.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# identify which gene have the greatest effect on z\n",
    "# by multiplying the means by the dense layer weight\n",
    "denseLayer = model.get_layer('dense_1')\n",
    "print(denseLayer.get_config())\n",
    "weights = denseLayer.get_weights()\n",
    "print(\"\\ntype(weights):{}\".format( type(weights) ))\n",
    "print(\"len(weights):{}\".format(len(weights)))\n",
    "print(\"weights[0][0:3]:{}\".format(weights[0][0:3]))\n",
    "print(\"len(weights[0]):{}\".format(len(weights[0])))\n",
    "print(\"type(weights[0]):{}\".format(type(weights[0])))\n",
    "print(\"len(weights[1]):{}\".format(len(weights[1])))\n",
    "coeficients = weights[0]\n",
    "print(\"coeficients.shape:{}\".format(coeficients.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00080593]\n",
      "[-0.00365209]\n"
     ]
    }
   ],
   "source": [
    "print(coeficients[0])\n",
    "print(coeficients[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WU0x7AgCZkh"
   },
   "outputs": [],
   "source": [
    "# last is the list of features,\n",
    "#lastTrain = normalTrainDF.columns[:-1]\n",
    "\n",
    "# select all the gene col lables. The last col is tumor_normal_value\n",
    "normalTrainFeatureCols =  normalTrainDF.columns[:-1]\n",
    "# print(\"type(lastTrain):{}\".format(type(lastTrain)))\n",
    "# print(\"lastTrain.shape:{}\".format(lastTrain.shape))\n",
    "# print(\"lastTrain:{}\".format(lastTrain))\n",
    "\n",
    "# normalTrainMeansSeries = normalTrainDF.loc['mean', last3ColLabels]\n",
    "normalTrainMeansSeries = normalTrainDF.loc['mean', normalTrainFeatureCols]\n",
    "normalTrainDF = None # clear memory\n",
    "\n",
    "# print(\"\\nnormalTrainMeansSeries.head:\\n{}\".format(normalTrainMeansSeries.head()))\n",
    "      \n",
    "# print(\"\\normalTrainMeansSeries.shape:{}\".format(normalTrainMeansSeries.shape))\n",
    "# print(\"type(normalTrainMeansSeries):{}\".format(type(normalTrainMeansSeries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUKPx006CZkk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalTrainMeansValues.shape:(58581,)\n",
      "type(normalTrainMeansValues):<class 'numpy.ndarray'>\n",
      "valuenormalTrainMeansValues:[[ 0.04585141]\n",
      " [-0.00849445]\n",
      " [ 0.07872539]\n",
      " ...\n",
      " [-0.00280762]\n",
      " [ 0.30552363]\n",
      " [-0.09099111]]\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 418 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.multiply.html\n",
    "# element wise multiplication\n",
    "normalTrainMeansValues = normalTrainMeansSeries.values\n",
    "normalTrainMeansSeries = None # clean memory\n",
    "print(\"normalTrainMeansValues.shape:{}\".format(normalTrainMeansValues.shape))\n",
    "\n",
    "# np.multiple multiply with shapes (58581,) * (58581, 1) exhasts memory\n",
    "s = normalTrainMeansValues.shape\n",
    "normalTrainMeansValues = np.reshape(normalTrainMeansValues, (s[0], 1))\n",
    "print(\"type(normalTrainMeansValues):{}\".format(type(normalTrainMeansValues)))\n",
    "# print(normalTrainMeansValues[0])\n",
    "# print(normalTrainMeansValues[1])\n",
    "# print(normalTrainMeansValues[2])\n",
    "print(\"valuenormalTrainMeansValues:{}\".format(normalTrainMeansValues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUKPx006CZkk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalTrainMeansValues.shape:(58581, 1)\n",
      "type(normalTrainMeansValues):<class 'numpy.ndarray'>\n",
      "coeficients.shape:(58581, 1)\n",
      "type(coeficients):<class 'numpy.ndarray'>\n",
      "Garbage collection thresholds: (700, 10, 10)\n",
      "Garbage collector: collected 0 objects.\n",
      "CPU times: user 64 ms, sys: 0 ns, total: 64 ms\n",
      "Wall time: 64.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# total crushes memory swap goes to 19.85 GB\n",
    "# <class 'numpy.ndarray'>\n",
    "# CPU times: user 11.6 s, sys: 12.8 s, total: 24.4 s\n",
    "# Wall time: 1min 15s\n",
    "print(\"normalTrainMeansValues.shape:{}\".format(normalTrainMeansValues.shape))\n",
    "print(\"type(normalTrainMeansValues):{}\".format(type(normalTrainMeansValues)))\n",
    "print(\"coeficients.shape:{}\".format(coeficients.shape))\n",
    "print(\"type(coeficients):{}\".format(type(coeficients)))\n",
    "\n",
    "# https://www.geeksforgeeks.org/garbage-collection-python/\n",
    "import gc \n",
    "# (threshold, allocations, deallocations)\n",
    "print(\"Garbage collection thresholds:\", gc.get_threshold()) \n",
    "\n",
    "# Returns the number of objects it has collected and deallocated \n",
    "collected = gc.collect() \n",
    "  \n",
    "# Prints Garbage collector  as 0 object \n",
    "print(\"Garbage collector: collected\", \"%d objects.\" % collected) \n",
    "\n",
    "# np.multiply generates MemoryError \n",
    "normalContribution = np.multiply(normalTrainMeansValues, coeficients) # element wise mult\n",
    "#normalContribution = normalTrainMeansValues * coeficients\n",
    "# n = normalTrainMeansValues.shape[0]\n",
    "# bucketSize = 5000\n",
    "# quotient, remainder = divmod(n,bucketSize)\n",
    "# print(\"\\nn:{} bucketSize:{} quotient:{} remainder:{}\\n\".format(n, bucketSize, quotient, remainder))\n",
    "# i = 0\n",
    "# q = 0\n",
    "# normalContribution = np.empty((n,1))\n",
    "# while i < n:\n",
    "#     if q < quotient:\n",
    "#         ll = bucketSize\n",
    "#     else:\n",
    "#         ll = remainder\n",
    "        \n",
    "#     ntmv = normalTrainMeansValues[i:i+ll]\n",
    "#     c = coeficients[i:i+ll]\n",
    "#     print(\"ntmv.shape{} c.shape:{}\".format(ntmv.reshape(ll,1).shape, c.shape))\n",
    "\n",
    "#     tmp = np.multiply(ntmv.reshape(ll,1), c)\n",
    "#     print(\"tmp.shape:{}\".format(tmp.shape))\n",
    "#     normalContribution[i:i+ll] = tmp\n",
    "#     q += 1\n",
    "#     i += ll\n",
    "#     print(\"i:{}, q:{}, ll:{}\".format(i, q, ll))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsDZ2vulCZko"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalContribution.shape:(58581, 1)\n",
      "normalContribution[0:4]:[[ 3.69530185e-05]\n",
      " [ 3.10225339e-05]\n",
      " [ 3.57093244e-04]\n",
      " [-2.48970414e-04]]\n",
      "normalContribution[-3:]:[[ 9.34205485e-06]\n",
      " [-4.02751563e-03]\n",
      " [ 3.43294116e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(\"normalContribution.shape:{}\".format(normalContribution.shape))\n",
    "print(\"normalContribution[0:4]:{}\".format(normalContribution[0:4]))\n",
    "print(\"normalContribution[-3:]:{}\".format(normalContribution[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([1, 2, 3]) + 2\n",
    "print(a)\n",
    "print(b)\n",
    "print(a * b)\n",
    "e = np.empty(a.shape)\n",
    "e[0:1] = a[0:1]\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a * b\n",
    "print(c)\n",
    "print(c[0])\n",
    "print(c[0:2])\n",
    "c[0:2] = c[0:2] + 10\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwbWWR6VCZkq"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# bins = numpy.linspace(-10, 10, 100)\n",
    "\n",
    "plt.hist(normalContribution, bins=50, alpha=0.5, label='normal')\n",
    "#pyplot.hist(y, bins=50, alpha=0.5, label='y')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3z0FsYcCZku"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0fGWkDrGCZk4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTrQfgHiCZk6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXlzolQMCZk8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6z5phOECZk-"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# yPredict = model.predict(XTestDF)\n",
    "# print(type(yPredict))\n",
    "# print(yPredict[0:3])\n",
    "\n",
    "# yTestPredict = [1 if p > 0.5 else 0 for p in yPredict]\n",
    "# #print(yTestPredict[0:3])\n",
    "# cf = confusion_matrix(yTestDF, yTestPredict)\n",
    "# print(cf)\n",
    "# expected = [[1707, 13],[8, 2098]]\n",
    "# np.testing.assert_array_equal(cf, expected)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "simpleModelFeatureSelection.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
